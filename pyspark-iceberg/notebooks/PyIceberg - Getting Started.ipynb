{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1041ae6f",
   "metadata": {},
   "source": [
    "![iceberg-logo](https://www.apache.org/logos/res/iceberg/iceberg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247fb2ab",
   "metadata": {},
   "source": [
    "### [Docker, Spark, and Iceberg: The Fastest Way to Try Iceberg!](https://tabular.io/blog/docker-spark-and-iceberg/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c8206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a9f41",
   "metadata": {},
   "source": [
    "## Load NYC Taxi/Limousine Trip Data\n",
    "\n",
    "For this notebook, we will use the New York City Taxi and Limousine Commision Trip Record Data that's available on the AWS Open Data Registry. This contains data of trips taken by taxis and for-hire vehicles in New York City. We'll save this into an iceberg table called `taxis`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747bee98",
   "metadata": {},
   "source": [
    "To be able to rerun the notebook several times, let's drop the table if it exists to start fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd09a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE DATABASE IF NOT EXISTS nyc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf9dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "DROP TABLE IF EXISTS nyc.taxis;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363f815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE TABLE IF NOT EXISTS nyc.taxis (\n",
    "    VendorID              bigint,\n",
    "    tpep_pickup_datetime  timestamp,\n",
    "    tpep_dropoff_datetime timestamp,\n",
    "    passenger_count       double,\n",
    "    trip_distance         double,\n",
    "    RatecodeID            double,\n",
    "    store_and_fwd_flag    string,\n",
    "    PULocationID          bigint,\n",
    "    DOLocationID          bigint,\n",
    "    payment_type          bigint,\n",
    "    fare_amount           double,\n",
    "    extra                 double,\n",
    "    mta_tax               double,\n",
    "    tip_amount            double,\n",
    "    tolls_amount          double,\n",
    "    improvement_surcharge double,\n",
    "    total_amount          double,\n",
    "    congestion_surcharge  double,\n",
    "    airport_fee           double\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (days(tpep_pickup_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47645b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "TRUNCATE TABLE nyc.taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fddb808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Jupyter\").getOrCreate()\n",
    "\n",
    "for filename in [\n",
    "    \"yellow_tripdata_2022-04.parquet\",\n",
    "    \"yellow_tripdata_2022-03.parquet\",\n",
    "    \"yellow_tripdata_2022-02.parquet\",\n",
    "    \"yellow_tripdata_2022-01.parquet\",\n",
    "    \"yellow_tripdata_2021-12.parquet\",\n",
    "]:\n",
    "    df = spark.read.parquet(f\"/home/iceberg/data/{filename}\")\n",
    "    df.write.mode(\"append\").saveAsTable(\"nyc.taxis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffd2c03",
   "metadata": {},
   "source": [
    "## Load data into a PyArrow Dataframe\n",
    "\n",
    "We'll fetch the table using the REST catalog that comes with the setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efee8252",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "from pyiceberg.expressions import GreaterThanOrEqual\n",
    "\n",
    "catalog = load_catalog('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794de3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = catalog.load_table('nyc.taxis')\n",
    "\n",
    "sc = tbl.scan(row_filter=GreaterThanOrEqual(\"tpep_pickup_datetime\", \"2022-01-01T00:00:00.000000+00:00\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.to_arrow().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e818e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(column='fare_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "stats.zscore(df['fare_amount'])\n",
    "\n",
    "# Remove everything larger than 3 stddev\n",
    "df = df[(np.abs(stats.zscore(df['fare_amount'])) < 3)]\n",
    "# Remove everything below zero\n",
    "df = df[df['fare_amount'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18771ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(column='fare_amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c8408",
   "metadata": {},
   "source": [
    "# DuckDB\n",
    "\n",
    "Use DuckDB to Query the PyArrow Dataframe directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "%sql duckdb:///:memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM df LIMIT 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5314f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql --save tip-amount --no-execute\n",
    "\n",
    "SELECT tip_amount\n",
    "FROM df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dec260",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sqlplot histogram --table df --column tip_amount --bins 22 --with tip-amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989827d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql --save tip-amount-filtered --no-execute\n",
    "\n",
    "WITH tip_amount_stddev AS (\n",
    "    SELECT STDDEV_POP(tip_amount) AS tip_amount_stddev\n",
    "    FROM df\n",
    ")\n",
    "\n",
    "SELECT tip_amount\n",
    "FROM df, tip_amount_stddev\n",
    "WHERE tip_amount > 0\n",
    "  AND tip_amount < tip_amount_stddev * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1df179",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sqlplot histogram --table tip-amount-filtered --column tip_amount --bins 50 --with tip-amount-filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2c62d",
   "metadata": {},
   "source": [
    "# Iceberg ❤️ PyArrow and DuckDB\n",
    "\n",
    "This notebook shows how you can load data into a PyArrow dataframe and query it using DuckDB easily. Iceberg allows you to take a slice out of the data that you need for your analysis, while reducing the time that you have to wait for the data and without polluting the memory with data that you're not going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a9c64d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
